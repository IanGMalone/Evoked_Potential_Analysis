{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis of Stimulus Triggered Averages\n",
    "*Ian Malone*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data and check structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Animal</th>\n",
       "      <th>Day_Postop</th>\n",
       "      <th>Day_Stim</th>\n",
       "      <th>Side</th>\n",
       "      <th>Stim_Amplitude</th>\n",
       "      <th>Sample</th>\n",
       "      <th>STA_Amplitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>N01</td>\n",
       "      <td>999</td>\n",
       "      <td>1</td>\n",
       "      <td>Left</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.014575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>N01</td>\n",
       "      <td>999</td>\n",
       "      <td>1</td>\n",
       "      <td>Left</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.007710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>N01</td>\n",
       "      <td>999</td>\n",
       "      <td>1</td>\n",
       "      <td>Left</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.002015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>N01</td>\n",
       "      <td>999</td>\n",
       "      <td>1</td>\n",
       "      <td>Left</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.001218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>N01</td>\n",
       "      <td>999</td>\n",
       "      <td>1</td>\n",
       "      <td>Left</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.003526</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Animal  Day_Postop  Day_Stim  Side  Stim_Amplitude  Sample  STA_Amplitude\n",
       "0    N01         999         1  Left            10.0       0      -0.014575\n",
       "1    N01         999         1  Left            10.0       1      -0.007710\n",
       "2    N01         999         1  Left            10.0       2      -0.002015\n",
       "3    N01         999         1  Left            10.0       3      -0.001218\n",
       "4    N01         999         1  Left            10.0       4      -0.003526"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "filename = 'df_STA_NEIL_2021_01_14'\n",
    "\n",
    "project = 'NEIL' if 'NEIL' in filename else 'SPARC'\n",
    "path = 'D:\\\\Dataframe_CSVs\\\\%s.csv' % filename\n",
    "\n",
    "df_sta = pd.read_csv(path)\n",
    "df_sta.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For this analysis, we will only keep the right side EMG for SPARC and left side EMG for Neilsen (for now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if 'NEIL' in path: \n",
    "    df_sta = df_sta[df_sta[\"Side\"] == 'Left']\n",
    "else:\n",
    "    df_sta = df_sta[df_sta[\"Side\"] == 'Right']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['N01' 'N04' 'N05' 'N09' 'N10' 'N11' 'N13' 'N14' 'N15' 'N16' 'N17' 'N19'\n",
      " 'N20' 'N21' 'N22' 'N23' 'N24' 'N25' 'N26' 'N27' 'N28' 'N29' 'N30' 'N31'\n",
      " 'N32' 'N33']\n",
      "[999   2   3   4   5   6   1]\n",
      "[1 2 3 4 0]\n",
      "['Left']\n",
      "[ 10.  20.  30.  40.  50.  60.  70.  80.  90. 100. 110. 120. 130. 140.\n",
      " 150. 160. 170. 180. 190. 200. 210. 220. 230. 240. 250. 260. 270. 280.\n",
      " 290. 300. 310. 320. 330. 340. 350. 360. 370. 380. 390. 400. 410. 420.\n",
      " 430. 440. 450. 490. 460. 470. 480. 500. 510. 520. 530. 540. 550. 560.\n",
      " 570. 580. 590. 600. 610. 620. 630. 640. 650. 660. 670. 680. 690. 700.\n",
      " 710. 720. 730. 740. 750. 760. 770. 780. 790. 800. 810. 820. 830. 840.\n",
      " 850. 860. 870. 880. 890. 900. 910.  15.  25.  35.  45.  55.  65.  75.\n",
      "  85.  95. 105. 115. 125. 135. 145. 155. 165. 175. 185. 195. 205. 215.\n",
      " 225. 235. 245. 255. 265. 275. 285. 295. 305. 315. 325. 335. 345. 355.\n",
      " 365. 375. 385. 395. 405. 415. 425. 435. 445. 455. 575. 735. 685.]\n"
     ]
    }
   ],
   "source": [
    "print(df_sta.Animal.unique())\n",
    "print(df_sta.Day_Postop.unique())\n",
    "print(df_sta.Day_Stim.unique())\n",
    "print(df_sta.Side.unique())\n",
    "print(df_sta.Stim_Amplitude.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add 'Time' column based on 'Sample' and a sampling frequency of 5000 Hz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Animal</th>\n",
       "      <th>Day_Postop</th>\n",
       "      <th>Day_Stim</th>\n",
       "      <th>Side</th>\n",
       "      <th>Stim_Amplitude</th>\n",
       "      <th>STA_Amplitude</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>N01</td>\n",
       "      <td>999</td>\n",
       "      <td>1</td>\n",
       "      <td>Left</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-0.014575</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>N01</td>\n",
       "      <td>999</td>\n",
       "      <td>1</td>\n",
       "      <td>Left</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-0.007710</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>N01</td>\n",
       "      <td>999</td>\n",
       "      <td>1</td>\n",
       "      <td>Left</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-0.002015</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>N01</td>\n",
       "      <td>999</td>\n",
       "      <td>1</td>\n",
       "      <td>Left</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-0.001218</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>N01</td>\n",
       "      <td>999</td>\n",
       "      <td>1</td>\n",
       "      <td>Left</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-0.003526</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Animal  Day_Postop  Day_Stim  Side  Stim_Amplitude  STA_Amplitude  Time\n",
       "0    N01         999         1  Left            10.0      -0.014575   0.0\n",
       "1    N01         999         1  Left            10.0      -0.007710   0.2\n",
       "2    N01         999         1  Left            10.0      -0.002015   0.4\n",
       "3    N01         999         1  Left            10.0      -0.001218   0.6\n",
       "4    N01         999         1  Left            10.0      -0.003526   0.8"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampling_frequency = 5000 # hertz\n",
    "df_sta['Time'] = df_sta['Sample']/sampling_frequency # create time column based on samples and sampling frequency\n",
    "df_sta['Time'] = df_sta['Time']*1000\n",
    "df_sta = df_sta.drop(columns=['Sample'])\n",
    "df_sta.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define function to add group information to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### groups for NEIL project\n",
    "injstim = ['N09','N10','N11','N13','N27','N28','N29','N30']\n",
    "noinjstim = ['N01','N04','N05','N31','N32','N33','N34','N35'] \n",
    "injnostim = ['N14','N15','N16','N21','N22','N23','N36','N37']\n",
    "noinjnostim = ['N17','N19','N20','N24','N25','N26','N38','N39'] \n",
    "\n",
    "### groups for SPARC project\n",
    "groupa = ['S01', 'S02']\n",
    "groupb = ['S03', 'S04']\n",
    "groupc = ['S05', 'S06']\n",
    "\n",
    "# add animal group information to the dataframe\n",
    "# make a function so you can apply to multiple dataframes\n",
    "def add_group(df):\n",
    "    '''This function adds Group column to dataframe based on Animal column'''\n",
    "    if project == 'NEIL':\n",
    "        conditions = [\n",
    "            (df['Animal'].isin(injstim)),\n",
    "            (df['Animal'].isin(noinjstim)),\n",
    "            (df['Animal'].isin(injnostim)),\n",
    "            (df['Animal'].isin(noinjnostim)) ]\n",
    "        choices = ['Yes Injury, Yes Stimulation', 'No Injury, Yes Stimulation', 'Yes Injury, No Stimulation', 'No Injury, No Stimulation']\n",
    "        df['Group'] = np.select(conditions, choices)\n",
    "    elif project == 'SPARC':\n",
    "        conditions = [\n",
    "            (df['Animal'].isin(groupa)),\n",
    "            (df['Animal'].isin(groupb)),\n",
    "            (df['Animal'].isin(groupc)) ]\n",
    "        choices = ['Group A', 'Group B', 'Group C']\n",
    "        df['Group'] = np.select(conditions, choices)       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot raw STAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# sns.set(font_scale=1)\n",
    "# plt.figure(figsize=(20,12))\n",
    "# # animal_list = ['N09']\n",
    "# # & (df_sta['Animal'].isin(animal_list))\n",
    "# stimlist = [150, 200, 250, 300, 350, 400, 450, 500]\n",
    "\n",
    "# ## you will need to subset df_sta to only plot certain stimulus amplitudes\n",
    "\n",
    "# g = sns.FacetGrid(df_sta[(df_sta['Stim_Amplitude'].isin(stimlist))], col='Day_Stim', row='Animal', hue='Stim_Amplitude')\n",
    "# g.map_dataframe(sns.lineplot, x='Time', y='STA_Amplitude')\n",
    "# g.set_axis_labels('Time (ms)', 'Ampltiude (V)')\n",
    "# g.add_legend()\n",
    "# #plt.savefig('C:\\\\Users\\\\Ian\\\\Downloads\\\\saving-a-seaborn-plot-as-pdf-file.pdf')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove stimulus artifact and re-plot STAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the stimulus artifact\n",
    "df_sta_noart = df_sta.copy()\n",
    "df_sta_noart = df_sta_noart[df_sta_noart['Time'] > 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# sns.set(font_scale=1)\n",
    "# plt.figure(figsize=(20,12))\n",
    "# animal_list = ['N09']\n",
    "# # & (df_sta['Animal'].isin(animal_list))\n",
    "# ## you will need to subset df_sta to only plot certain stimulus amplitudes\n",
    "\n",
    "# g = sns.FacetGrid(df_sta_noart[(df_sta_noart['Stim_Amplitude'].isin(stimlist)) & (df_sta['Animal'].isin(animal_list))], col='Day_Stim', row='Animal', hue='Stim_Amplitude')\n",
    "# g.map_dataframe(sns.lineplot, x='Time', y='STA_Amplitude')\n",
    "# g.set_axis_labels('Time (ms)', 'Ampltiude (V)')\n",
    "# g.add_legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Based on the plotted STAs, remove unusable data from dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete N29 from dataframe (recordings were badly messed up)\n",
    "\n",
    "df_sta_noart = df_sta_noart[df_sta_noart['Animal'] != 'N29']\n",
    "df_sta_noart['Animal'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Peak-to-peak (p2p) amplitude analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_p2p = df_sta_noart[df_sta_noart['Time'] <= 15].copy()\n",
    "df_p2p.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calclated p2p amplitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_p2p = df_p2p.groupby(['Animal', 'Day_Stim', 'Stim_Amplitude'])['STA_Amplitude'].apply(lambda x: x.max() + abs(x.min())).reset_index().rename(columns={'STA_Amplitude':'p2p_amplitude'})\n",
    "df_p2p.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert all p2p amplitudes into ratios of the animal's max p2p amplitude over all 4 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all p2p amplitudes into ratios of the animal's max p2p amplitude\n",
    "\n",
    "df_p2p_ratio_max = df_p2p.merge(df_p2p.groupby(['Animal'])['p2p_amplitude'].max(), on='Animal', how='left')\n",
    "df_p2p_ratio_max['p2p_ratio_max'] = df_p2p_ratio_max['p2p_amplitude_x'] / df_p2p_ratio_max['p2p_amplitude_y']\n",
    "df_p2p_ratio_max = df_p2p_ratio_max.drop(columns=['p2p_amplitude_x', 'p2p_amplitude_y'])\n",
    "df_p2p_ratio_max.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add group information to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_group(df_p2p_ratio_max)\n",
    "df_p2p_ratio_max.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_p2p_ratio_max.groupby(['Animal'])['Day_Stim'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For the Neilsen project, exclude day 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if project == 'NEIL':\n",
    "    df_p2p_ratio_max = df_radf_p2p_ratio_maxtio_max[df_p2p_ratio_max['Day_Stim']>0]\n",
    "    \n",
    "df_p2p_ratio_max.groupby(['Animal'])['Day_Stim'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Peak-to-peak latency analysis (3.75 ms time bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bin = df_sta_noart[df_sta_noart['Time'] <= 15].copy()\n",
    "df_bin['Bin'] = pd.cut(df_bin.Time, \n",
    "                bins=[0,3.75,7.5,11.25], \n",
    "                include_lowest=True, \n",
    "                labels=['0-3.75ms','3.75-7.5ms','7.5-11.25ms'])\n",
    "df_bin = df_bin.dropna()\n",
    "df_bin.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_p2p_latency = df_bin.copy()\n",
    "df_p2p_latency = df_p2p_latency.groupby(['Animal', 'Day_Stim', 'Stim_Amplitude', 'Bin'])['STA_Amplitude'].apply(lambda x: x.max() + abs(x.min())).reset_index().rename(columns={'STA_Amplitude':'p2p_amplitude'})\n",
    "df_p2p_latency.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_p2p_latency = df_p2p_latency.merge(df_p2p_latency.groupby(['Animal'])['p2p_amplitude'].max(), on='Animal', how='left')\n",
    "df_p2p_latency['p2p_ratio_max'] = df_p2p_latency['p2p_amplitude_x'] / df_p2p_latency['p2p_amplitude_y']\n",
    "df_p2p_latency = df_p2p_latency.drop(columns=['p2p_amplitude_x', 'p2p_amplitude_y'])\n",
    "df_p2p_latency.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_group(df_p2p_latency)\n",
    "df_p2p_latency.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_p2p_latency_mean = df_p2p_latency.groupby(['Group', 'Day_Stim', 'Stim_Amplitude', 'Bin'])['p2p_ratio_max'].agg('mean').reset_index().rename(columns={'p2p_ratio_max':'mean_p2p_ratio_max'}).copy()\n",
    "df_p2p_latency_mean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_p2p_latency_mean['Day_Stim'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stimamps = [200, 220, 240, 260, 280, 300, 320, 340, 360, 380, 400]\n",
    "days = [0, 12]\n",
    "\n",
    "df_plot = df_p2p_latency_mean[df_p2p_latency_mean['Stim_Amplitude'].isin(stimamps) & df_p2p_latency['Day_Stim'].isin(days)].copy()\n",
    "df_plot = df_plot.rename(columns={\"Bin\": \"Time Bin\", \"mean_p2p_ratio_max\": \"Mean Peak-to-Peak Amplitude (mV)\", 'Day_Stim':'Day'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(font_scale=2)\n",
    "sns.set_style(\"ticks\")\n",
    "g = sns.FacetGrid(df_plot, col=\"Group\", size=6, palette='tab10')\n",
    "g = (g.map(sns.scatterplot, \"Time Bin\", \"Mean Peak-to-Peak Amplitude (mV)\", 'Day', s=75).add_legend())\n",
    "plt.savefig('D:\\\\test.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Area under the curve analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Area under the curve latency analysis (3.75 ms time bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_auc_latency = df_bin.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot all p2p amplitudes to get a general idea of what the data look like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "stim_amp_list = [200, 250, 300, 350, 400, 450, 500, 600]\n",
    "\n",
    "plt.figure(figsize=(20,20))\n",
    "sns.set_style(\"ticks\")\n",
    "g = sns.FacetGrid(df_ratio_max[df_ratio_max['Stim_Amplitude'].isin(stim_amp_list)], col=\"Group\")\n",
    "g = (g.map(sns.scatterplot, \"Stim_Amplitude\", \"p2p_ratio_max\", 'Day_Stim').add_legend())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_auc['Day_Stim'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(20,20))\n",
    "sns.set_style(\"ticks\")\n",
    "g = sns.FacetGrid(df_auc, col=\"Group\")\n",
    "g = (g.map(sns.scatterplot, \"Stim_Amplitude\", \"STA_AUC\", 'Day_Stim').add_legend())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ratio_max.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(x=\"Stim_Amplitude\", y=\"p2p_ratio_max\", col=\"Group\", hue=\"Day_Stim\", data=df_ratio_max,\n",
    "           col_wrap=2, ci=None, palette=\"muted\", height=4,\n",
    "           scatter_kws={\"s\": 50, \"alpha\": 0.2})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit lines by group and day to visualize change over time (and stim amplitude) for each group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ratio_max = df_ratio_max.rename(columns={\"p2p_ratio_max\": \"Normalized Peak to Peak Amplitude\", \"Stim_Amplitude\": \"Stimulation Amplitude (uA)\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ratio_max = df_ratio_max.rename(columns={\"Day_Stim\": \"Day\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ratio_max.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.lmplot(x=\"Stimulation Amplitude (uA)\", y=\"Normalized Peak to Peak Amplitude\", col=\"Group\", hue=\"Day\", data=df_ratio_max,\n",
    "           col_wrap=2, order=1, ci=95, palette=\"muted\", height=4,\n",
    "           scatter_kws={\"s\": 50, \"alpha\": 0.2})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate statistics on the plotted lines above\n",
    "##### slope, intercept, r_value, p_value, std_err"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make dataframes for each group. This will make it easier to subset in the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group: no injury, no stimulation\n",
    "df_nn = df_ratio_max[df_ratio_max['Group'] == 'No Injury, No Stimulation']\n",
    "df_nn1 = df_nn[df_nn['Day_Stim'] == 1]\n",
    "df_nn2 = df_nn[df_nn['Day_Stim'] == 2]\n",
    "df_nn3 = df_nn[df_nn['Day_Stim'] == 3]\n",
    "df_nn4 = df_nn[df_nn['Day_Stim'] == 4]\n",
    "\n",
    "# group: no injury, yes stimulation\n",
    "df_ny = df_ratio_max[df_ratio_max['Group'] == 'No Injury, Yes Stimulation']\n",
    "df_ny1 = df_ny[df_ny['Day_Stim'] == 1]\n",
    "df_ny2 = df_ny[df_ny['Day_Stim'] == 2]\n",
    "df_ny3 = df_ny[df_ny['Day_Stim'] == 3]\n",
    "df_ny4 = df_ny[df_ny['Day_Stim'] == 4]\n",
    "\n",
    "# group: yes injury, no stimulation\n",
    "df_yn = df_ratio_max[df_ratio_max['Group'] == 'Yes Injury, No Stimulation']\n",
    "df_yn1 = df_yn[df_yn['Day_Stim'] == 1]\n",
    "df_yn2 = df_yn[df_yn['Day_Stim'] == 2]\n",
    "df_yn3 = df_yn[df_yn['Day_Stim'] == 3]\n",
    "df_yn4 = df_yn[df_yn['Day_Stim'] == 4]\n",
    "\n",
    "# group: yes injury, yes stimulation\n",
    "df_yy = df_ratio_max[df_ratio_max['Group'] == 'Yes Injury, Yes Stimulation']\n",
    "df_yy1 = df_yy[df_yy['Day_Stim'] == 1]\n",
    "df_yy2 = df_yy[df_yy['Day_Stim'] == 2]\n",
    "df_yy3 = df_yy[df_yy['Day_Stim'] == 3]\n",
    "df_yy4 = df_yy[df_yy['Day_Stim'] == 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import statsmodels.api as sm\n",
    "\n",
    "df = df_yy4\n",
    "\n",
    "X = df['Stim_Amplitude']\n",
    "y = df['p2p_ratio_max']\n",
    "\n",
    "X2 = sm.add_constant(X)\n",
    "est = sm.OLS(y, X2)\n",
    "est2 = est.fit()\n",
    "print(est2.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply linear mixed effects model (random slopes) to data plotted above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ratio_max.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "md = sm.MixedLM.from_formula(\"p2p_ratio_max ~ Stim_Amplitude + Day_Stim\", df_ratio_max, groups=df_ratio_max[\"Group\"])\n",
    "\n",
    "mdf = md.fit()\n",
    "\n",
    "print(mdf.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate area under the stimulus triggered average curves \n",
    "##### For each current amplitude, each animal, and each day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#### KEEP THIS. MAY SPLIT INTO TIME BINS IN FUTURE\n",
    "\n",
    "# bins = [0.001, 0.004, 0.007, 0.010, 0.013, 0.0298] # define bins\n",
    "# labels = ['1 to 4 ms', '4 to 7 ms', '7 to 10 ms', '10 to 13 ms', '13 to 29.8 ms'] # define bin labels\n",
    "# #labels = [1, 2, 3, 4, 5]\n",
    "\n",
    "# df_bin = df_sta_sub_norm.copy()\n",
    "# df_bin['Time_Bin'] = pd.cut(df_bin['Time'], bins, labels=labels, right=False) # add Time_Bin column to dataframe\n",
    "# df_bin = df_bin.reindex(columns=['Animal', 'Day', 'Side', 'Stim_Amplitude', 'Time', 'Time_Bin', 'STA_Scaled'])\n",
    "# df_bin.rename(columns = {'Time_Bin':'Bin'}, inplace = True) \n",
    "# df_bin = df_bin[df_bin['Bin'] != '13 to 29.8 ms'] # drop all data 13 ms after the stimulation\n",
    "# df_bin.head()\n",
    "\n",
    "\n",
    "# from scipy import integrate\n",
    "\n",
    "# df_auc = df_bin.groupby(['Animal', 'Day', 'Side', 'Stim_Amplitude', 'Bin'])['STA_Scaled'].apply(integrate.simps).reset_index()\n",
    "# df_auc.rename(columns = {'STA_Scaled':'STA_AUC'}, inplace = True)\n",
    "# df_auc = df_auc.dropna()\n",
    "# df_auc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_noisefloor_auc = df_sta_noart.copy()\n",
    "df_noisefloor_auc = df_noisefloor_auc[(df_noisefloor_auc['Time'] > 20.0)]\n",
    "df_noisefloor_auc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_auc = df_sta_noart.copy()\n",
    "df_auc = df_auc[(df_auc['Time'] > 2.0) & (df_auc['Time'] < 10.2)]\n",
    "df_auc.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# define animal groups\n",
    "injstim = ['N09','N10','N11','N13','N27','N28','N29','N30']\n",
    "noinjstim = ['N01','N04','N05','N31','N32','N33','N34','N35'] \n",
    "injnostim = ['N14','N15','N16','N21','N22','N23','N36','N37']\n",
    "noinjnostim = ['N17','N19','N20','N24','N25','N26','N38','N39'] \n",
    "\n",
    "# add animal group information to the dataframe\n",
    "conditions = [\n",
    "    (df_auc['Animal'].isin(injstim) ),\n",
    "    (df_auc['Animal'].isin(noinjstim) ),\n",
    "    (df_auc['Animal'].isin(injnostim) ),\n",
    "    (df_auc['Animal'].isin(noinjnostim) )]\n",
    "choices = ['Injury and Stimulation', 'No Injury and Stimulation', 'Injury and No Stimulation', 'No Injury and No Stimulation']\n",
    "df_auc['Group'] = np.select(conditions, choices)\n",
    "df_auc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_noisefloor_peak = df_noisefloor_auc.copy()\n",
    "df_noisefloor_peak = df_noisefloor_peak.groupby(['Animal', 'Day_Postop', 'Day_Stim', 'Side', 'Stim_Amplitude'])['STA_Amplitude'].agg('mean').reset_index()\n",
    "df_noisefloor_peak = df_noisefloor_peak.rename(columns={\"STA_Amplitude\": \"STA_Noise_Floor\"})\n",
    "df_noisefloor_peak.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_noisefloor_auc = df_noisefloor_auc.groupby(['Animal', 'Day_Postop', 'Day_Stim', 'Side', 'Stim_Amplitude'])['STA_Amplitude'].agg('mean').reset_index()\n",
    "df_noisefloor_auc['STA_Amplitude'] = df_noisefloor_auc['STA_Amplitude'] * 7.8 # 7.8 because the length of the STA is 7.8 ms\n",
    "df_noisefloor_auc = df_noisefloor_auc.rename(columns={\"STA_Amplitude\": \"STA_Noise_Floor\"})\n",
    "df_noisefloor_auc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_peak = df_auc.copy()\n",
    "df_peak = df_peak.groupby(['Animal', 'Day_Postop', 'Day_Stim', 'Side', 'Stim_Amplitude', 'Group'])['STA_Amplitude'].agg('max').reset_index()\n",
    "df_peak.rename(columns = {'STA_Amplitude':'STA_Peak'}, inplace = True)\n",
    "df_peak = df_peak.drop(columns=['Day_Postop', 'Side'])\n",
    "df_peak.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now need to integrate the stimulus triggered average curves to find the area beneath them. We can then compare these areas under the curve (AUCs) between groups, days, stimulus intensities, etc.\n",
    "\n",
    "The trapezoidal rule provides a simple way to integrate a function but typically has much larger error than Simpson's rule without saving significant compute time. We will use Simpson's rule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import integrate\n",
    "\n",
    "df_auc = df_auc.groupby(['Animal', 'Day_Postop', 'Day_Stim', 'Side', 'Stim_Amplitude', 'Group'])['STA_Amplitude'].apply(integrate.simps).reset_index()\n",
    "df_auc.rename(columns = {'STA_Amplitude':'STA_AUC'}, inplace = True)\n",
    "df_auc = df_auc.drop(columns=['Day_Postop', 'Side'])\n",
    "df_auc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_peak.to_csv('D:\\\\df_peak_raw.csv', index=False) \n",
    "# df_auc.to_csv('D:\\\\df_auc_raw.csv', index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encoding for injury condition and stimulation condition\n",
    "\n",
    "choices = ['Injury and Stimulation', 'No Injury and Stimulation', 'Injury and No Stimulation', 'No Injury and No Stimulation']\n",
    "\n",
    "def injury(row):\n",
    "    if (row['Group'] == 'Injury and Stimulation') | (row['Group'] == 'Injury and No Stimulation'):\n",
    "        val = 1\n",
    "    elif (row['Group'] == 'No Injury and Stimulation') | (row['Group'] == 'No Injury and No Stimulation'):\n",
    "        val = 0\n",
    "    else:\n",
    "        val = -1\n",
    "    return val\n",
    "\n",
    "def stimulation(row):\n",
    "    if (row['Group'] == 'Injury and Stimulation') | (row['Group'] == 'No Injury and Stimulation'):\n",
    "        val = 1\n",
    "    elif (row['Group'] == 'Injury and No Stimulation') | (row['Group'] == 'No Injury and No Stimulation'):\n",
    "        val = 0\n",
    "    else:\n",
    "        val = -1\n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# percent change from noise floor to peak for each day\n",
    "\n",
    "df_peak_change = df_peak.copy()\n",
    "df_peak_change[\"STA_Noise_Floor\"] = df_noisefloor_peak[\"STA_Noise_Floor\"]\n",
    "df_peak_change['STA_Percent_Noise_Floor'] = ((df_peak_change['STA_Peak'].sub(df_peak_change[\"STA_Noise_Floor\"])).div(df_peak_change[\"STA_Noise_Floor\"])).mul(100)\n",
    "df_peak_change.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_peak_change['Injury'] = df_peak_change.apply(injury, axis=1)\n",
    "df_peak_change['Stimulation'] = df_peak_change.apply(stimulation, axis=1)\n",
    "df_peak_change = df_peak_change.drop(columns=['STA_Peak', 'STA_Noise_Floor'])\n",
    "df_peak_change.rename(columns = {'STA_Percent_Noise_Floor':'Peak_Percent_Noise_Floor'}, inplace = True) \n",
    "df_peak_change.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mean_day_peak_change = df_peak_change.copy()\n",
    "df_mean_day_peak_change = df_mean_day_peak_change.groupby(['Day_Stim', 'Stim_Amplitude', 'Group'])['Peak_Percent_Noise_Floor'].agg('mean').reset_index()\n",
    "df_mean_day_peak_change = df_mean_day_peak_change.rename(columns={'Peak_Percent_Noise_Floor':'Mean_Peak_Percent_Noise_Floor'})\n",
    "df_mean_day_peak_change.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stim_amp_list = [200, 250, 300, 350, 400, 450, 500, 600]\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(20,20))\n",
    "# sns.set(font_scale=2)\n",
    "sns.set_style(\"ticks\")\n",
    "g = sns.FacetGrid(df_mean_day_peak_change[(df_mean_day_peak_change['Stim_Amplitude'].isin(stim_amp_list)) & (df_mean_day_peak_change['Day_Stim']>0)], col=\"Group\")\n",
    "g = (g.map(sns.scatterplot, \"Stim_Amplitude\", \"Mean_Peak_Percent_Noise_Floor\", 'Day_Stim').add_legend())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# percent change from noise floor to auc for each day\n",
    "\n",
    "df_day_auc_change = df_auc.copy()\n",
    "df_day_auc_change[\"STA_Noise_Floor\"] = df_noisefloor_auc[\"STA_Noise_Floor\"]\n",
    "df_day_auc_change['STA_Percent_Noise_Floor'] = ((df_day_auc_change['STA_AUC'].sub(df_day_auc_change[\"STA_Noise_Floor\"])).div(df_day_auc_change[\"STA_Noise_Floor\"])).mul(100)\n",
    "df_day_auc_change.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_day_auc_change['Injury'] = df_day_auc_change.apply(injury, axis=1)\n",
    "df_day_auc_change['Stimulation'] = df_day_auc_change.apply(stimulation, axis=1)\n",
    "#df_day_pchange = df_day_pchange.drop(columns=['Day_Postop', 'Side', 'STA_AUC', 'STA_Noise_Floor'])\n",
    "#df_day_pchange.to_csv('D:\\\\df_abstract.csv', index=False) \n",
    "# df_day_pchange.head(50)\n",
    "df_day_auc_change = df_day_auc_change.drop(columns=['STA_AUC', 'STA_Noise_Floor'])\n",
    "df_day_auc_change.rename(columns = {'STA_Percent_Noise_Floor':'AUC_Percent_Noise_Floor'}, inplace = True) \n",
    "\n",
    "df_day_auc_change.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cluster = df_day_auc_change.copy()\n",
    "df_cluster = df_cluster.drop(columns=['Injury','Stimulation'])\n",
    "df_cluster = df_cluster.set_index('Animal')\n",
    "df_cluster = df_cluster[df_cluster['Stim_Amplitude'] < 800]\n",
    "# df_cluster['AnimalID'] = [int(x.strip()[-2:]) for x in df_cluster['Animal']]\n",
    "# df_cluster = df_cluster.drop(columns=['Animal'])\n",
    "# df_cluster = df_cluster[(df_cluster['Day_Stim'] == 3) | (df_cluster['Day_Stim'] == 4)]\n",
    "# df_cluster = df_cluster[(df_cluster['Stim_Amplitude'] > 299) & (df_cluster['Stim_Amplitude'] < 510)]\n",
    "# df_cluster = df_cluster.groupby(['AnimalID', 'Injury', 'Stimulation', ])['AUC_Percent_Noise_Floor'].agg('mean').reset_index()\n",
    "df_cluster.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "sns.set(style = \"darkgrid\")\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection = '3d')\n",
    "\n",
    "x = df_cluster['Day_Stim']\n",
    "y = df_cluster['Stim_Amplitude']\n",
    "z = df_cluster['AUC_Percent_Noise_Floor']\n",
    "\n",
    "ax.set_xlabel(\"Day_Stim\")\n",
    "ax.set_ylabel(\"Stim_Amplitude\")\n",
    "ax.set_zlabel(\"AUC_Percent_Noise_Floor\")\n",
    "\n",
    "ax.scatter(x, y, z)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cluster.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AgglomerativeClustering(distance_threshold=0, n_clusters=None, affinity='euclidean', \n",
    "                                     linkage='complete').fit(df_cluster)\n",
    "Z = hierarchy.linkage(model.children_, 'complete')\n",
    "plt.figure(figsize=(20,10))\n",
    "dn = hierarchy.dendrogram(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "clustering = AgglomerativeClustering(distance_threshold=0, n_clusters=None, affinity='euclidean', \n",
    "                                     linkage='complete').fit(df_day_auc_change)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from scipy.cluster.hierarchy import dendrogram\n",
    "from scipy.cluster import hierarchy\n",
    "\n",
    "Z = hierarchy.linkage(clustering.children_, 'complete')\n",
    "\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "dn = hierarchy.dendrogram(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_day_auc_change.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cluster = df_day_auc_change[df_day_auc_change['Stim_Amplitude']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_timeseries = df_auc.copy()\n",
    "df_timeseries['Injury'] = df_timeseries.apply(injury, axis=1)\n",
    "df_timeseries['Stimulation'] = df_timeseries.apply(stimulation, axis=1)\n",
    "df_timeseries.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# from scipy.cluster.hierarchy import dendrogram\n",
    "\n",
    "# def plot_dendrogram(model, **kwargs):\n",
    "#     # Create linkage matrix and then plot the dendrogram\n",
    "\n",
    "#     # create the counts of samples under each node\n",
    "#     counts = np.zeros(model.children_.shape[0])\n",
    "#     n_samples = len(model.labels_)\n",
    "#     for i, merge in enumerate(model.children_):\n",
    "#         current_count = 0\n",
    "#         for child_idx in merge:\n",
    "#             if child_idx < n_samples:\n",
    "#                 current_count += 1  # leaf node\n",
    "#             else:\n",
    "#                 current_count += counts[child_idx - n_samples]\n",
    "#         counts[i] = current_count\n",
    "\n",
    "#     linkage_matrix = np.column_stack([model.children_, model.distances_,\n",
    "#                                       counts]).astype(float)\n",
    "\n",
    "#     # Plot the corresponding dendrogram\n",
    "#     dendrogram(linkage_matrix, **kwargs)\n",
    "    \n",
    "# plt.title('Hierarchical Clustering Dendrogram')\n",
    "# # plot the top three levels of the dendrogram\n",
    "# plot_dendrogram(clustering, truncate_mode='level', p=3)\n",
    "# plt.xlabel(\"Number of points in node (or index of point if no parenthesis).\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_auc = df_sta_noart[df_sta_noart['Time'] <= 15].copy()\n",
    "add_group(df_auc)\n",
    "df_auc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_auc['STA_Amplitude'] = df_auc['STA_Amplitude'].abs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_auc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import integrate\n",
    "\n",
    "df_auc = df_auc.groupby(['Animal', 'Day_Postop', 'Day_Stim', 'Side', 'Stim_Amplitude', 'Group'])['STA_Amplitude'].apply(integrate.simps).reset_index()\n",
    "df_auc.rename(columns = {'STA_Amplitude':'STA_AUC'}, inplace = True)\n",
    "df_auc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_auc.to_csv('D:\\\\CSV_Outputs\\\\df_auc.csv', index=False) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # these are dataframes that erica requested for abstract\n",
    "\n",
    "# df_peak_400 = df_peak_change.copy()\n",
    "# df_peak_day4 = df_peak_change.copy()\n",
    "# df_auc_400 = df_day_pchange.copy()\n",
    "# df_auc_day4 = df_day_pchange.copy()\n",
    "\n",
    "# df_peak_400 = df_peak_400[df_peak_400['Stim_Amplitude'] == 400]\n",
    "# df_peak_day4 = df_peak_day4[df_peak_day4['Day_Stim'] == 4]\n",
    "# df_auc_400 = df_auc_400[df_auc_400['Stim_Amplitude'] == 400]\n",
    "# df_auc_day4 = df_auc_day4[df_auc_day4['Day_Stim'] == 4]\n",
    "\n",
    "# df_peak_400.to_csv('D:\\\\df_peak_400.csv', index=False) \n",
    "# df_peak_day4.to_csv('D:\\\\df_peak_day4.csv', index=False) \n",
    "# df_auc_400.to_csv('D:\\\\df_auc_400.csv', index=False) \n",
    "# df_auc_day4.to_csv('D:\\\\df_auc_day4.csv', index=False) \n",
    "\n",
    "# df_peak_400_day4 = df_peak_400.copy()\n",
    "# df_peak_400_day4 = df_peak_400_day4[df_peak_400_day4['Day_Stim'] == 4]\n",
    "\n",
    "# df_auc_400_day4 = df_auc_400.copy()\n",
    "# df_auc_400_day4 = df_auc_400_day4[df_auc_400_day4['Day_Stim'] == 4]\n",
    "\n",
    "# df_peak_400_day4.to_csv('D:\\\\df_peak_400_day4.csv', index=False) \n",
    "# df_auc_400_day4.to_csv('D:\\\\df_auc_400_day4.csv', index=False) \n",
    "\n",
    "# df_auc = df_day_pchange.copy()\n",
    "# df_peak = df_peak_change.copy()\n",
    "# df_auc.to_csv('D:\\\\df_auc.csv', index=False) \n",
    "# df_peak.to_csv('D:\\\\df_peak.csv', index=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CODE BELOW THIS NEEDS TO BE INTEGRATED TO CODE ABOVE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # function to calculate percent change\n",
    "# def perc_change_from_d4(df, day):\n",
    "#     return ((df[str(day)].sub(df['4'])).div(df['4'])).mul(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### changed function above to take df arg\n",
    "\n",
    "# df_auc_pchange = df_auc.pivot_table(index=['Animal', 'Side', 'Stim_Amplitude', 'Bin', 'Group'], \n",
    "#                     columns='Day', \n",
    "#                     values='STA_AUC').reset_index()\n",
    "\n",
    "# for n in np.arange(6,20,2):\n",
    "#     df_auc_pchange[\"Day 4 to Day %s\" % n] = perc_change_from_d4(n)\n",
    "\n",
    "# df_auc_pchange = df_auc_pchange.drop(df_auc_pchange.columns[5:13], axis=1)\n",
    "# df_auc_pchange.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_auc_pchange = pd.melt(df_auc_pchange, id_vars=['Animal', 'Side', 'Stim_Amplitude', 'Bin', 'Group'], var_name='Days', value_name='Percent_Change')\n",
    "# df_auc_pchange.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_auc_pchange[(df_auc_pchange['Group'] == 'Group C') & (df_auc_pchange['Days'] == 'Day 4 to Day 16') & (df_auc_pchange['Animal'] == 'S05')].head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # all the bar plots\n",
    "# sns.set(font_scale=1.5)\n",
    "# g = sns.FacetGrid(df_auc_pchange, col=\"Days\", row='Bin')\n",
    "# g.map(sns.barplot, \"Group\", \"Percent_Change\", 'Stim_Amplitude')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# day_range = 'Day 4 to Day 18'\n",
    "\n",
    "# plt.figure(figsize=(20,12))\n",
    "# sns.set(font_scale=2)\n",
    "# sns.set_style(\"ticks\")\n",
    "# ax = sns.boxplot(x='Group', y='Percent_Change', hue='Stim_Amplitude', data=df_auc_pchange[df_auc_pchange['Days'] == day_range])\n",
    "# ax.legend(loc=\"upper left\", title='Stimulation Amplitude (uA)', title_fontsize=\"small\")\n",
    "# ax.set_title(project + ': Percent Change AUC ' + day_range)\n",
    "# ax.set_ylabel('Percent Change STA AUC')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other analyses\n",
    "\n",
    "- Peak to peak from stimulus triggered average for each current amplitude, each animal, each day\n",
    "- Latency from stimulus pulse to stimulus triggered average for each current amplitude, each animal, each day\n",
    "- Time domains of stimulus triggered average\n",
    "- Differences in any of these parameters based on time of day?\n",
    "- How are we going to present the impedance data in the Neilsen paper? Im still not clear on this.\n",
    "- Additional things we can look at (e.g., wavelet, FFT, HMM, etc.)\n",
    "- Look in manuscript file for notes on ideas. Also look in Daily Notes on OneNote for papers that did EMG analysis well.\n",
    "- Add information on time of day and stimulus amplitude from Neurochip"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
